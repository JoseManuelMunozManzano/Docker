Kubernates (K8s)

01 - Introducción
-----------------
  Es un administrador (orquestador) de un conjunto grande de contenedores.
  ¿Qué problemas resuelve y por qué vale la pena utilizarlo?
  Queremos que las aplicaciones se estén ejecutando 24/7 y que cuando haya que hacer cambios
  estos puedan hacerse en caliente, también llamado 99.9% uptime.
  También queremos un sistema tolerante a fallos y que se pueda escalar hacia arriba o abajo según
  demanda.
  Esto puede conseguirse usando Kubernetes.

  En esta introducción vamos a hablar de ocho componentes:
  - Pod: Unidad más básica que tiene Kubernetes. Si tenemos una imagen, el pod sería una capa extra que
        se coloca sobre esa imagen. De esta manera Kubernetes puede crear réplicas de nuestra imagen y
        tener contenedores.
        El Pod indica cuántas réplicas tiene, cual es la dirección IP para poder comunicarse con el...
        El problema de los contenedores dentro de un pod es que todos tienen una IP volátil.
        Si cambio una imagen por otra, aun siendo la misma, nos va a dar otra dirección IP.
        Esto dificulta la comunicación entre la red interna que está creando todo este cluster de pods.
  - Services: Solucionan el problema de la comunicación entre Pods. Los servicios tienen una dirección
        IP única, y los contenedores dentro de los pods también. La idea es que el Servicio se conecte 
        al Pod y yo hago referencia a las direcciones del servicio (y este sabe como comunicarse con el Pod)
        Ahora, si reemplazamos imágenes dentro del Pod, gracias al Servicio, podemos mantener la
        comunicación, porque el ciclo de vida del Pod y del Servicio son independientes.
        Hay dos tipos de servicios:
          * Internos
          * Externos
  - Ingress: Nos permite hacer la comunicación entre nuestro cluster y el mundo exterior, ya que las
        solicitudes a nuestro sitio web, por ejemplo, entra primero por ingress y este a los respectivos
        servicios.
        También va a tener todo lo demás de nuestro cluster protegido y cerrado. Mantiene la seguridad 
        de nuestras aplicaciones.
  - Secrets: Es un par key - value. Los secrets nos permiten definir estos pares de valores.
        Son variables de entorno privadas hacia el exterior, pero visibles en todo mi cluster.
        Están codificados como un Base64 String.
        Por defecto, Kubernetes tampoco maneja la encriptación.
  - ConfigMap: Básicamente son iguales a los Secrets, con la diferencia de que en vez de estar
        codificados en Base64, son un simple JSON, es decir, están abiertos y todo el mundo
        puede verlos. Es útil cuando queremos grabar la URL de la BD, un usuario que no es privado.
        Son variables de entorno públicas.
  - Volumes: Dado nuestro cluster, los volúmenes serían como discos duros que le vamos conectando
        para poder tener persistencia de datos. Por defecto, Kubernetes NO mantiene la persistencia
        de la data.
  - Deployments: Es un plano de como construir el Pod, como levantarlo, que variables de entorno
        va a usar, las réplicas que va a tener...
        Aquí es donde puede escalar arriba o abajo las réplicas.
        Los Servicios los haremos dentro del Deployment porque suelen ir de la mano, en archivos
        YAML.
  - StatefulSet: Es el plano similar a los deployments, pero para bases de datos principalmente.
        Pero usualmente no se usan configuraciones de la BD en el cluster,
        porque no es nada sencillo.
        La información donde se graba la BD suele almacenarse en un servicio especializado de BD.
  
  Un cluster es un grupo de nodos que corren aplicaciones en contenedores de una forma eficiente,
  automatizada, distribuida y escalable.

  La idea al finalizar todo esto es que tengamos una compresión de qué es Kubernetes.

02 - Instalación y configuración de MiniKube
--------------------------------------------
  Documentación de MiniKube
    https://minikube.sigs.k8s.io/docs/

  MiniKube ayuda a las personas que están entrando a aprender Kubernetes a manejarlo y tener una
  configuración rápidamente.
  Crea un contenedor que ya viene preconfigurado con Kubernetes para que ahí administremos nuestro
  cluster.
  Es como tener un contenedor que tiene un contenedor interno que controla otros contenedores internos.

  - Para la instalación de MniKube, en la página web de documentación de arriba, pulsar en Get Started!
  - En la parte de Installation seleccionar la arquitectura y el proceso de selección (usando Homebrew)
  - Seguimos las indicaciones de instalación de la web.
  - Para sustituir una instalación antigua de MiniKube (fallará la instalación) usando brew:
      brew unlink minikube
      brew link minikube
  - Para confirmar que MiniKube se ha instalado correctamente
      minikube version

  - Inicializar cluster
  - Escribir en la consola
      minikube start
    
    Este comando hace varias descargas y la configuración.
    Crea la imagen, el contenedor y el volumen en Docker.

  - Estos tres apuntes son solo como documentación. No hay que hacerlo.
  - Para interactuar con MiniKube usar el comando
      kubectl get po -A
  - Para interacturar directamente con el cluster dentro de MiniKube
      minikube kubectl -- get po -A
  - Si queremos borrar todos los clusters y el contenedor.
      minikube delete --all

  - Dejamos el contenedor ejecutándose.

  - NOTA: Aplicación de consola gráfica que puede ser interesante ver.
      https://k9scli.io/

03 - ConfigMap
--------------
  Vamos a trabajar en el proyecto 14-k8s-teslo

  Va a ser todo un cluster de Kubernetes para el manejo de nuestra aplicación de Teslo. Es una API
  y vamos a instalar postgres y PgAdmin.

  También tener en cuenta esta documentación de Kubernetes.
    https://kubernetes.io/es/docs/concepts/
  Hay snippets de código que vamos a usar en este proyecto.

  Vamos a empezar por lo que menos configuraciones tiene. Vamos a ocupar una BD Postgres.
  En la vida real usaríamos un servicio o aprovisionaríamos una BD en la nube y haríamos la
  conexión mediante una cadena de conexión.

  - Creamos en la carpeta 14-k8s-teslo el archivo
      postgres-config.yml

    El objetivo es crear nuestro ConfigMap con las variables de entorno públicas que se van a compartir
    a lo largo de mi aplicación.

  - En la documentación buscar ConfigMap y vamos a esta página.
      https://kubernetes.io/docs/concepts/configuration/configmap/
   
    Cogemos el snippet de como luce un ConfigMap y lo pegamos a nuestro archivo postgres-config.yml. Tras los cambios queda:

apiVersion: v1
kind: ConfigMap
metadata:
  # Este es el nombre del archivo de configuración que realmente importa,
  # no el nombre que le hemos puesto al archivo.
  # Este nombre lo usaré luego para hacer referencia a mis key-values pairs
  name: postgres-config
data:
  DB_NAME: postgres
  # DB_HOST es el nombre del servidor donde esta el servicio de la BD.
  # Todavía no lo tenemos definido, y eso es correcto, pero sabemos que lo vamos a tener
  # dentro de algo que se llama postgres-service. Recordar que un servicio ya tiene una
  # dirección de IP fija
  DB_HOST: postgres-service
  # Tiene que ser manejado como un string.
  DB_PORT: '5432'

04 - Secrets
------------
  Vamos a tener como secretos el usuario de la BD y el password del usuario root de la BD.

  - Creamos en el raiz de nuestro proyecto el archivo postgres-secrets.yml

  - En la documentación indicada al principio del punto 03, buscar Secrets, y vamos a esta página.
      https://kubernetes.io/docs/concepts/configuration/secret/

  - Recordar que los valores de los secretos tienen que pasar por un Base64 string encoded.
      https://codebeautify.org/base64-encode
  - Otra opción en vez de usar esa web es la siguiente, que funciona en Mac, Linux y PowerShell:
      echo -n postgres | base64

  - Nuestro archivo postgres-secrets.yml queda de la siguiente manera:

apiVersion: v1
kind: Secret
metadata:
  name: postgres-secrets
type: Opaque
data:
  # Base64 string encoded
  # https://codebeautify.org/base64-encode
  # postgres ==> cG9zdGdyZXM=
  DB_USER: cG9zdGdyZXM=
  # EstoEsUnPassWordSecreto ==>  RXN0b0VzVW5QYXNzV29yZFNlY3JldG8=
  DB_PASSWORD: RXN0b0VzVW5QYXNzV29yZFNlY3JldG8=

  IMPORTANTE: Muchas personas lo que hacen con los archivos de configuración de Kubernetes, es subirlos
  a un repositorio para darle seguimiento del mismo.

05 - Pods, Services y Deployments
---------------------------------
  Lo normal es crear un deployment que ya viene con la configuración del Pod.

  - Creamos en el raiz de nuestro proyecto el archivo postgres.yml

  - En la documentación indicada al principio del punto 03, buscar Deployments, y vamos a esta página.
      https://kubernetes.io/docs/concepts/workloads/controllers/deployment/

  - En la documentación indicada al principio del punto 03, buscar Services, y vamos a esta página.
      https://kubernetes.io/es/docs/concepts/services-networking/service/

  - Cogemos los snippet de como luce un Deployment y un Service y los pegamos a nuestro archivo postgres.yml y los modificamos a nuestro gusto. Queda:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres-deployment
  labels:
    app: postgres
# La definición de nuestro Pod vienen en este spec
spec:
  # Copias de nuestro Pod
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    # Este spec es la definición de los contenedores que vamos a querer montar y sus
    # respectivas variables de entorno.
    spec:
      containers:
        - name: postgres
          image: postgres:15.1
          ports:
            - containerPort: 5432
          env:
            - name: POSTGRES_PASSWORD
              # Obteniendo el valor de mi fichero postgres-secrets.yml
              # Se indica el nombre de la variable de entorno y de donde la obtiene.
              valueFrom:
                secretKeyRef:
                  name: postgres-secrets
                  key: DB_PASSWORD
# Estos --- es para indicar que voy a empezar un nuevo archivo aquí abajo
# Vamos con el servicio
---
apiVersion: v1
kind: Service
metadata:
  # Este nombre de servicio es el que pusimos en el archivo postgres-config.yml en DB_HOST
  # Va a permitir conectarse a la BD indicada en la parte del Deployment
  name: postgres-servicio
spec:
  selector:
    app: postgres
  ports:
    - protocol: TCP
      # port puede ser cualquier puerto. Todo el mundo fuera de este servicio va a tener que
      # utilizar ese port para conectarse al puerto 5432 de targetPort que está enlazado con
      # el container en la parte del Deployment.
      # Usualmente se suele indicar en port el mismo puerto que es necesario tener en targetPort
      port: 5432
      # El puerto que se va a conectar con el containerPort indicado en la parte Deployment.
      targetPort: 5432

06 - Desplegar la BD en el cluster
----------------------------------
  - Nos vamos a la carpeta del proyecto.
    Tenemos que tener corriendo el contenedor minikube

  - Para ver la versión de kubectl
      kubectl version

  - Para verificar
      kubectl get all
    Si da algún error es porque algo pasa con el contenedor. Borrarlo y regenerarlo con:
      minikube start

  - Vamos a ejecutar los archivos yaml de configuración dentro de nuestro cluster.
    Técnicamente no importa el orden siempre y cuando no haya dependencias.
    Vamos a empezar con el fichero postgres-config.yml, luego postgres-secrets.yml y por último postgres.yml

      kubectl apply -f postgres-config.yml
      kubectl apply -f postgres-secrets.yml
      kubectl apply -f postgres.yml

  - Volvemos a ejecutar la verificación de pods, services y deployments.
    Lo importante es que aparezcan con READY con valor 1/1
    Esperar un poco y volver a probar el mandato. Se tiene que descargar la imagen, hacer la configuración
    y se levantó la BD, y eso lleva cierto tiempo.
      kubectl get all

  - ¿Cómo saber si algo fue mal?
    Para ver información, tenemos que copiar el nombre (es bastante largo) y ejecutar el mandato
      kubectl describe deployment.apps/postgres-deployment

    Esto nos da información sobre el Pod, la cantidad de réplicas, puertos, variables de entorno (secretos)
    Para saber que todo está bien, al final indica Type. Si su valor es Normal entonces todo va bien.
    Por desgracia no hay mucha información.

  - Para ver los logs, se hace sobre el pod, no sobre el deployment.
      kubectl logs pod/postgres-deployment-6475d989b5-g4gdx

    Ahí ya indica que la BD ya está lista para recibir conexiones.

07 - Agregar PGAdmin al cluster
-------------------------------
  - Vamos a instalar el servicio de PGAdmin para poder administrar la BD
    En concreto, en DockerHub buscaremos la imagen dpage/pgadmin4
      https://hub.docker.com/r/dpage/pgadmin4
  
  - Copiamos nuestro archivo postgres-secrets.yml y creamos uno nuevo con nombre pg-admin-secrets.yml

apiVersion: v1
kind: Secret
metadata:
  name: pg-admin-secrets
type: Opaque
data:
  # Base64 string encoded
  # echo -n superman@google.com | base64
  PG_USER_EMAIL: c3VwZXJtYW5AZ29vZ2xlLmNvbQ==
  # EstoEsUnPassWordSecreto ==>  RXN0b0VzVW5QYXNzV29yZFNlY3JldG8=
  PG_PASSWORD: RXN0b0VzVW5QYXNzV29yZFNlY3JldG8=

  - Creamos un archivo nuevo llamado pg-admin.yml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: pg-admin-deployment
  labels:
    app: pg-admin
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pg-admin
  template:
    metadata:
      labels:
        app: pg-admin
    spec:
      containers:
        - name: pg-admin
          image: dpage/pgadmin4:6.17
          ports:
            # https://hub.docker.com/layers/dpage/pgadmin4/6.17/images/sha256-b04d64352af918043489fca0d95f2a87480238ac5d071fcafd24d6a38f18389d?context=explore
            # Aquí vemos que se exponen los puertos 443 o 80
            - containerPort: 80
          env:
            - name: PGADMIN_DEFAULT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: pg-admin-secrets
                  key: PG_PASSWORD
            - name: PGADMIN_DEFAULT_EMAIL
              valueFrom:
                secretKeyRef:
                  name: pg-admin-secrets
                  key: PG_USER_EMAIL
            - name: PGADMIN_CONFIG_ENHANCED_COOKIE_PROTECTION
              value: 'false'
---
apiVersion: v1
kind: Service
metadata:
  name: pg-admin-servicio
spec:
  # Necesitamos exponer el targetPort al mundo exterior para poder hacer la parte del Ingress.
  # NodePort nos permite colocar esa comunicación externa.
  type: NodePort
  selector:
    app: pg-admin
  ports:
    - protocol: TCP
      port: 80 # cualquier puerto
      targetPort: 80
      # El puerto del NodePort debe estar entre el 30000 y el 32767
      # Esta en la documentación: https://kubernetes.io/es/docs/concepts/services-networking/service/
      nodePort: 30200

08 - Desplegar PGAdmin al cluster
---------------------------------
  - Añadimos PgAdmin al cluster
      kubectl apply -f pg-admin-secrets.yml
      kubectl apply -f pg-admin.yml

  - Vemos como va todo. Lo importante es que aparezcan con READY con valor 1/1
      kubectl get all

  - Depurar el deployment
      kubectl describe pod/pg-admin-deployment-6894bfd99d-dp5v4

  - Si volvemos a ver como va todo, veremos que ahora READY indica 0/1 con un STATUS CrashLoopBackOff
      kubectl get all

  - Si vemos los logs para buscar el error
      kubectl logs pod/pg-admin-deployment-6894bfd99d-dp5v4

    Vemos:
    
      NameError: name 'false' is not defined. Did you mean: 'False'?
      usage: gunicorn [OPTIONS] [APP_MODULE]
      gunicorn: error: argument -t/--timeout: invalid int value: ''

    Corregimos el error:
        - name: PGADMIN_CONFIG_ENHANCED_COOKIE_PROTECTION
          value: 'False'    

  - Tenemos que volver a aplicar lo que cambió.
      kubectl apply -f pg-admin.yml
    
    Cambia el name, cuidado!

  - Vemos como va todo. Lo importante es que aparezcan con READY con valor 1/1
      kubectl get all

  - Si vemos los logs vemos que ahora todo está correcto
      kubectl logs pod/pg-admin-deployment-76ffd4ff94-z9dkz

  - Técnicamente ya está todo expuesto al mundo exterior. 
    Esto sería todo y podríamos acceder a la web usando el puerto 30200.
  
    PERO!!! Como todo está corriendo dentro de nuestro contenedor minikube tenemos
    que exponer ese contenedor (el servicio) a mi computadora.
      kubectl get all

      minikube service pg-admin-servicio 

    Nos abre automáticamente la web de pgAdmin en el navegador.
    Indicar en login lo que tenemos en pg-admin-secrets.yml

      superman@google.com
      EstoEsUnPassWordSecreto

    Intentar crear la conexión a la base de datos (ver postgres-secrets.yml y postgres.yml)
      Click en Servers
      Click en Register > Server
      Colocar el nombre de: "HeroesDB" (el nombre no importa)
      Ir a la pestaña de connection
      Colocar el hostname "postgres-servicio" (el mismo nombre que le dimos al service)
      Username es "postgres" y el password: EstoEsUnPassWordSecreto
      Probar la conexión      

  - Para terminar la comunicación con minikube, en el terminal pulsar Ctrl+C

09 - Agregar el BackendApp al Cluster
-------------------------------------
  - Vamos a agregar la imagen del backend
      https://hub.docker.com/r/klerith/k8s-teslo-backend

  - Vamos a usar la versión 1.1.0
    NOTA: Siempre es mejor usar una versión concreta en vez del latest, porque pueden que la hayan
    cambiado e introduzca breaking changes.

  - Necesitamos un secret nuevo para el JWT_SECRET

  - Nos vamos a la carpeta de nuestro proyecto y copiamos el archivo pg-admin-secrets.yml y lo
    renombramos a backend-secrets.yml y lo dejamos así:
  
apiVersion: v1
kind: Secret
metadata:
  name: backend-secrets
type: Opaque
data:
  # Base64 string encoded
  # echo -n estoEsMiSecretDeK8s | base64
  JWT_SECRET: ZXN0b0VzTWlTZWNyZXREZUs4cw==

  - Hacemos un nuevo archivo de deployment copiado de pg-admin.yml. Lo llamamos backend.yml
